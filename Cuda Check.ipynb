{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU:  1\n",
      "GPU Name:  NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Number of GPU: \", torch.cuda.device_count())\n",
    "print(\"GPU Name: \", torch.cuda.get_device_name())\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:567:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2722:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm_dmix.c:1000:(snd_pcm_dmix_open) unable to open slave\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available audio input devices:\n",
      "7: pipewire\n",
      "8: default\n",
      "9: Family 17h/19h HD Audio Controller Analog Stereo\n",
      "10: soundcore R50i-83\n",
      "11: Google Chrome\n",
      "12: Google Chrome-78\n",
      "13: soundcore R50i\n",
      "14: Bluetooth internal capture stream for soundcore R50i\n",
      "15: Google Chrome input\n",
      "\u001b[92m You\u001b[0m\n",
      "\u001b[92m You\u001b[0m\n",
      "\u001b[92m\u001b[0m\n",
      "Stopping...\n"
     ]
    }
   ],
   "source": [
    "import wave\n",
    "import pyaudio\n",
    "import os\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "NEON_GREEN = \"\\033[92m\"\n",
    "RESET_COLOR = \"\\033[0m\"\n",
    "\n",
    "def list_input_devices(p):\n",
    "    print(\"Available audio input devices:\")\n",
    "    for i in range(p.get_device_count()):\n",
    "        device_info = p.get_device_info_by_index(i)\n",
    "        if device_info.get(\"maxInputChannels\") > 0:\n",
    "            print(f\"{i}: {device_info.get('name')}\")\n",
    "    device_index = int(input(\"Enter the device index of your preferred microphone: \"))\n",
    "    return device_index\n",
    "\n",
    "def record_chunk(p, stream, chunk_file):\n",
    "    CHUNK_SIZE = 1024\n",
    "    RECORD_SECONDS = 4\n",
    "    frames = []\n",
    "\n",
    "    for _ in range(0, int(16000 / CHUNK_SIZE * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK_SIZE, exception_on_overflow=False)\n",
    "        frames.append(data)\n",
    "\n",
    "    if frames:\n",
    "        with wave.open(chunk_file, 'wb') as wf:\n",
    "            wf.setnchannels(1)\n",
    "            wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "            wf.setframerate(16000)\n",
    "            wf.writeframes(b''.join(frames))\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def transcribe_chunk(model, file_path):\n",
    "    segments, info = model.transcribe(file_path)\n",
    "    return \" \".join([segment.text for segment in segments])\n",
    "\n",
    "def initialize_model():\n",
    "    model_size = \"medium.en\"\n",
    "    return WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "stream = None\n",
    "\n",
    "try:\n",
    "    device_index = list_input_devices(p)\n",
    "    model = initialize_model()\n",
    "    \n",
    "    stream = p.open(\n",
    "        format=pyaudio.paInt16,\n",
    "        channels=1,\n",
    "        rate=16000,\n",
    "        input=True,\n",
    "        frames_per_buffer=1024,\n",
    "        input_device_index=device_index if device_index != 8 else None  # Use 'default' if selected\n",
    "    )\n",
    "    \n",
    "    accumulated_transcription = \"\"\n",
    "    \n",
    "    while True:\n",
    "        chunk_file = \"temp_chunk.wav\"\n",
    "        if record_chunk(p, stream, chunk_file):\n",
    "            transcription = transcribe_chunk(model, chunk_file)\n",
    "            print(NEON_GREEN + transcription + RESET_COLOR)\n",
    "            accumulated_transcription += transcription + \" \"\n",
    "            os.remove(chunk_file)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopping...\")\n",
    "    with open(\"log.txt\", \"w\") as log_file:\n",
    "        log_file.write(accumulated_transcription)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "finally:\n",
    "    if stream is not None:\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "    p.terminate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faster-whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
